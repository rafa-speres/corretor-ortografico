{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Corretor Ortografico\n",
        "**Desenvolvido para corrigir erro por letra faltante, por letra a mais, por letras trocadas e inversão de letras**\n",
        "\n",
        "**O corretor desenvolvido é capaz de corrigir palavras a um erro da palavra correta, vide que, a tentativa de desenvolver um corretor para \"erros mais distantes\"  resultou em corretores de menor precisão**\n",
        "\n",
        "**Isso pode ser explicado pela grande quantidade de palavras semelhantes entre si que existem quando o método procura por 2 ou mais erros, levando a palavra mais provavel não sendo a certa para um número grande de casos**\n",
        "\n"
      ],
      "metadata": {
        "id": "oKIH_QyvXEl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/sample_data/artigos.txt', 'r') as f:\n",
        "  base_conhecimento = f.read()\n",
        "\n",
        "print(base_conhecimento[:300])\n",
        "\n",
        "# 'base_conhecimento' e' a variavel que possui toda a base de conhecimento utilizada pelo problema (corpus textual) (fornecido pela alura)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHynOyPfyDqr",
        "outputId": "894879fc-3070-4f81-a07d-186becd88b2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "imagem \n",
            "\n",
            "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
            "\n",
            "java\n",
            "\n",
            "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(base_conhecimento) #num de caracteres do corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOPz6bi4yUEg",
        "outputId": "c2bb0fff-1d36-4b42-fb71-49582f5f63db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2605046"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# biblioteca utilizada para tokenizacao do corpus textual (permitindo aplicação das tecnicas de Processamento de Linguagem Natural - NLP)\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K02uIJdC0fX6",
        "outputId": "198fced5-6733-45bb-b998-24e864e84bf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#funcao recebe a lista de tokens gerada pela nltk.tokenize.word sobre o corpus textual, retornando uma lista de palavras (sem pontos de interrogacao, exclamacao, etc)\n",
        "def separa_palavras(lista_tokens):\n",
        "  lista_palavras = []\n",
        "  for token in lista_tokens:\n",
        "    if token.isalpha():\n",
        "      lista_palavras.append(token)\n",
        "  return lista_palavras"
      ],
      "metadata": {
        "id": "9IZ6X43808pf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#processo de tokenizacao do corpus textual\n",
        "lista_tokens = nltk.tokenize.word_tokenize(base_conhecimento)\n",
        "lista_palavras = separa_palavras(lista_tokens)\n",
        "print(f\"numero de palavras: {len(lista_palavras)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvEpJZCp1uY2",
        "outputId": "b7849fd6-aca6-4c6f-f731-f65a70b78c15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero de palavras: 316137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a funcao normalizacao garante que todas as palavras da lista de palavras estejam em letra minuscula, facilitando e aumentando a qualidade do Processamento de Linguagem natural\n",
        "def normalizacao(lista_palavras):\n",
        "  lista_normalizada = []\n",
        "  for palavra in lista_palavras:\n",
        "    lista_normalizada.append(palavra.lower())\n",
        "  return lista_normalizada"
      ],
      "metadata": {
        "id": "UBw3Pc6w2C3P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_normalizada = normalizacao(lista_palavras)\n",
        "total_palavras = len(lista_normalizada)"
      ],
      "metadata": {
        "id": "QYh_tGk22u0K"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"numero de palavras únicas no copus textual: {len(set(lista_normalizada))}\")\n",
        "#essa informacao indica o \"tamanho\" da base de conhecimento utilziada no processo\n",
        "#para referencia, estima-se que sejam necessarias cerca de 8000 palavras para atingir fluencia em um idioma \n",
        "#fonte: <https://hridiomas.com/quantas-palavras-voce-precisa-saber-para-ser-fluente/>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csPp7yOj3joO",
        "outputId": "28dbcc64-8cef-4589-d1e6-a2502e4b8bc3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero de palavras únicas no copus textual: 16381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**E + letra + Direito**"
      ],
      "metadata": {
        "id": "p-5nqL6ok0mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#uso de nltk.FreqDist() para armazenar a distribuicao de frequencias das palavras presentes no corpus textual\n",
        "frequencia = nltk.FreqDist(lista_normalizada)\n",
        "frequencia.most_common(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8TmK988BFgk",
        "outputId": "1203469b-b4a2-44c1-c999-a4fc4fde4915"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 12284),\n",
              " ('o', 11022),\n",
              " ('que', 9534),\n",
              " ('a', 8740),\n",
              " ('e', 8232),\n",
              " ('para', 6047),\n",
              " ('um', 4976),\n",
              " ('é', 4690),\n",
              " ('uma', 4105),\n",
              " ('do', 3986),\n",
              " ('em', 3760),\n",
              " ('com', 3719),\n",
              " ('como', 3020),\n",
              " ('no', 2631),\n",
              " ('da', 2611)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#funcao recebe uma palavra gerada pelos metodos, de forma a dividir a frequencia dessa palavra pelo total de palavras, retornando assim a probabilidade dessa palavra\n",
        "def probabilidade(palavra_gerada):\n",
        "  return frequencia[palavra_gerada]/total_palavras"
      ],
      "metadata": {
        "id": "scGzKBVPBd_N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As funcaoes para geracao de palavras recebem as fatias esquerda (E) e direita(D) da palavra. Essas fatias sao realizadas pela funcao gerador_palavras()**\n",
        "\n",
        "**Ex do modelo de fatias (com a palavra NLTK)**\n",
        "> 1° fatia: _+NLTK (E = NULL) (D = NLTK)\n",
        "\n",
        "> 2° fatia: N+LTK (E = N) (D = LTK)\n",
        "\n",
        "> 3° fatia: NL+TK (E = NL) (D = TK)\n",
        "\n",
        "> 4° fatia: NLT+K (E = NLT) (D = K)\n",
        "\n",
        "> 5° fatia: NLTK+_ (E = NLTK) (D = NULL)\n"
      ],
      "metadata": {
        "id": "-f_3eIqOiAqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insere Letra\n",
        "E + letra + D"
      ],
      "metadata": {
        "id": "ZJwn0BAAkOtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insere_letra(fatias):\n",
        "  novas_palavras = []\n",
        "  letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "  for E, D in fatias:\n",
        "    for letra in letras:\n",
        "      novas_palavras.append(E + letra + D)\n",
        "  return novas_palavras"
      ],
      "metadata": {
        "id": "-tvPaEx0hZ_e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deleta Letra\n",
        "E + D[1: ]\n"
      ],
      "metadata": {
        "id": "xd-cUwIgkVCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deleta_letra(fatias):\n",
        "  novas_palavras = []\n",
        "  for E, D in fatias:\n",
        "    novas_palavras.append(E + D[1:])\n",
        "    \n",
        "  return novas_palavras"
      ],
      "metadata": {
        "id": "d9csH7aWhpSA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Troca Letra\n",
        "E + letra + D[1: ]"
      ],
      "metadata": {
        "id": "wVVE0ZNEk_rH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def troca_letra(fatias):\n",
        "  novas_palavras = []\n",
        "  letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "  for E, D in fatias:\n",
        "    for letra in letras:\n",
        "      novas_palavras.append(E + letra + D[1:])\n",
        "  \n",
        "  return novas_palavras"
      ],
      "metadata": {
        "id": "Ov0M8foBhmQm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inverte Letra\n",
        "E + D[1] + D[0] + D[2: ]"
      ],
      "metadata": {
        "id": "i55FPaiMlNNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inverte_letra(fatias):\n",
        "  novas_palavras = []\n",
        "  for E, D in fatias:\n",
        "    if len(D) > 1:\n",
        "      novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
        "  \n",
        "  return novas_palavras"
      ],
      "metadata": {
        "id": "Ka25CJsbhh1V"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#recebe uma palavra, gera as fatias da palavra e chama as funcoes para geracao de apalvras (passando as fatias como argumento)\n",
        "#retorna as palavras geradas\n",
        "def gerador_palavras(palavra):\n",
        "  fatias = []\n",
        "  for i in range(len(palavra)+1):\n",
        "    fatias.append((palavra[:i], palavra[i:]))\n",
        "\n",
        "  palavras_geradas = insere_letra(fatias)\n",
        "  palavras_geradas += deleta_letra(fatias)\n",
        "  palavras_geradas += troca_letra(fatias)\n",
        "  palavras_geradas += inverte_letra(fatias)\n",
        "  \n",
        "  return palavras_geradas"
      ],
      "metadata": {
        "id": "LAnfcqY17Ibq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funcao recebe uma palavra, passa essa palavra pelo gerador de palavras e retorna a palavra de maior probabilidade entra as geradas\n",
        "def corretor(palavra):\n",
        "  palavras_geradas = gerador_palavras(palavra)\n",
        "\n",
        "   #calcula a probabilidade para cada uma das palavras geradas e retorna a de maior probabilidade\n",
        "  palavra_correta = max(palavras_geradas, key = probabilidade)\n",
        "  return palavra_correta"
      ],
      "metadata": {
        "id": "HlCfKqEM_rJd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funcao recebe o arquivo com as palavras que serao usadas para testar o corretor, retornando uma lista de palavras teste com cada elemento respeitando formato:\n",
        "#(correta, errada)\n",
        "def cria_dados_teste(nome_arquivo):\n",
        "  lista_palavras_teste = []\n",
        "  f = open(nome_arquivo, 'r')\n",
        "  for linha in f:\n",
        "    correta, errada = linha.split()\n",
        "    lista_palavras_teste.append((correta, errada))\n",
        "  f.close()\n",
        "  return lista_palavras_teste"
      ],
      "metadata": {
        "id": "hiFzO6z1Dmvs"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_teste = cria_dados_teste('/content/sample_data/palavras.txt')"
      ],
      "metadata": {
        "id": "EtoW7VxEES6g"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funcao avaliador recebe os testes e da um print da taxa de acerto acompanhado do numero de palavas\n",
        "def avaliador(testes):\n",
        "  numero_palavras = len(testes)\n",
        "  acertou = 0\n",
        "  for correta, errada in testes:\n",
        "    palavra_corrigida = corretor(errada)\n",
        "    if palavra_corrigida == correta:\n",
        "      acertou += 1\n",
        "  taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "  print(f'{taxa_acerto}% de {numero_palavras} palavras')"
      ],
      "metadata": {
        "id": "uCGAg3wDCMgA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado do corretor para o corpus textual e testes utilizados\n"
      ],
      "metadata": {
        "id": "wVVO90bulcsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avaliador(lista_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBdP4Szhg_A9",
        "outputId": "2db52514-dcb7-46da-ae2c-84ca20340f0c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.34% de 186 palavras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "daNAfS_j7pXg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}